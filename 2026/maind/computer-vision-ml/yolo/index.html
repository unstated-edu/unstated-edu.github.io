<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>YOLOv8 (ONNX) Webcam — Vanilla JS</title>
    <style>
      body {
        margin: 0;
      }
      #wrap {
        position: relative;
        width: 350px;
        height: 350px;
        overflow: hidden;
      }
      video,
      canvas {
        position: absolute;
        inset: 0;
        width: 100%;
        height: 100%;
        object-fit: cover;
      }
 

    </style>

    <!-- ONNX Runtime Web via CDN (script tag quick start) -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  </head>
  <body>
    <div id="hud">loading…</div>

    <div id="wrap">
      <video id="video" autoplay playsinline muted></video>
      <canvas id="overlay"></canvas>
    </div>

    <button id="start">Start</button>

    <script>
      // COCO-80 labels (YOLOv8 default)
      const COCO_CLASSES = [
        "person",
        "bicycle",
        "car",
        "motorcycle",
        "airplane",
        "bus",
        "train",
        "truck",
        "boat",
        "traffic light",
        "fire hydrant",
        "stop sign",
        "parking meter",
        "bench",
        "bird",
        "cat",
        "dog",
        "horse",
        "sheep",
        "cow",
        "elephant",
        "bear",
        "zebra",
        "giraffe",
        "backpack",
        "umbrella",
        "handbag",
        "tie",
        "suitcase",
        "frisbee",
        "skis",
        "snowboard",
        "sports ball",
        "kite",
        "baseball bat",
        "baseball glove",
        "skateboard",
        "surfboard",
        "tennis racket",
        "bottle",
        "wine glass",
        "cup",
        "fork",
        "knife",
        "spoon",
        "bowl",
        "banana",
        "apple",
        "sandwich",
        "orange",
        "broccoli",
        "carrot",
        "hot dog",
        "pizza",
        "donut",
        "cake",
        "chair",
        "couch",
        "potted plant",
        "bed",
        "dining table",
        "toilet",
        "tv",
        "laptop",
        "mouse",
        "remote",
        "keyboard",
        "cell phone",
        "microwave",
        "oven",
        "toaster",
        "sink",
        "refrigerator",
        "book",
        "clock",
        "vase",
        "scissors",
        "teddy bear",
        "hair drier",
        "toothbrush",
      ];

      const INPUT_SIZE = 640;
      const SCORE_THRESH = 0.5;
      const IOU_THRESH = 0.7;

      const video = document.getElementById("video");
      const overlay = document.getElementById("overlay");
      const hud = document.getElementById("hud");
      const startBtn = document.getElementById("start");

      const octx = overlay.getContext("2d");

      // offscreen canvas for preparing model input (640x640)
      const off = document.createElement("canvas");
      off.width = INPUT_SIZE;
      off.height = INPUT_SIZE;
      const offctx = off.getContext("2d", { willReadFrequently: true });

      let session = null;
      let inputName = null;
      let running = false;

      function clamp(v, min, max) {
        return Math.max(min, Math.min(max, v));
      }

      function iou(box1, box2) {
        const [x1, y1, x2, y2] = box1;
        const [x1b, y1b, x2b, y2b] = box2;

        const xi1 = Math.max(x1, x1b);
        const yi1 = Math.max(y1, y1b);
        const xi2 = Math.min(x2, x2b);
        const yi2 = Math.min(y2, y2b);

        const interW = Math.max(0, xi2 - xi1);
        const interH = Math.max(0, yi2 - yi1);
        const inter = interW * interH;

        const a1 = Math.max(0, x2 - x1) * Math.max(0, y2 - y1);
        const a2 = Math.max(0, x2b - x1b) * Math.max(0, y2b - y1b);
        const uni = a1 + a2 - inter;

        return uni <= 0 ? 0 : inter / uni;
      }

      // Parse YOLOv8 ONNX output shaped like: [1, 84, 8400] flattened
      // First 4 rows: xc, yc, w, h ; next rows: class scores
      function processOutput(output, imgW, imgH) {
        const boxes = [];
        const numCandidates = 8400;
        const numClasses = COCO_CLASSES.length;

        for (let i = 0; i < numCandidates; i++) {
          // find best class for this candidate
          let bestClass = 0;
          let bestScore = 0;

          for (let c = 0; c < numClasses; c++) {
            const score = output[numCandidates * (c + 4) + i];
            if (score > bestScore) {
              bestScore = score;
              bestClass = c;
            }
          }

          if (bestScore < SCORE_THRESH) continue;

          const xc = output[i];
          const yc = output[numCandidates + i];
          const w = output[2 * numCandidates + i];
          const h = output[3 * numCandidates + i];

          // map from 640-space to image space (we feed stretched 640x640)
          const x1 = ((xc - w / 2) / INPUT_SIZE) * imgW;
          const y1 = ((yc - h / 2) / INPUT_SIZE) * imgH;
          const x2 = ((xc + w / 2) / INPUT_SIZE) * imgW;
          const y2 = ((yc + h / 2) / INPUT_SIZE) * imgH;

          boxes.push([x1, y1, x2, y2, COCO_CLASSES[bestClass], bestScore]);
        }

        // NMS
        boxes.sort((a, b) => b[5] - a[5]);
        const result = [];
        while (boxes.length) {
          const chosen = boxes.shift();
          result.push(chosen);
          for (let j = boxes.length - 1; j >= 0; j--) {
            // same-class NMS feels nicer; remove this condition if you want global NMS
            if (
              boxes[j][4] === chosen[4] &&
              iou(chosen, boxes[j]) > IOU_THRESH
            ) {
              boxes.splice(j, 1);
            }
          }
        }
        return result;
      }

      function drawBoxes(boxes) {
        const w = overlay.width;
        const h = overlay.height;

        octx.clearRect(0, 0, w, h);
        octx.lineWidth = 3;
        octx.font = "16px ui-monospace, Menlo, monospace";

        for (let [x1, y1, x2, y2, label, score] of boxes) {
          // If values look normalized (0..1), convert to pixels
          const normalized = x2 <= 1.2 && y2 <= 1.2; // quick heuristic
          if (normalized) {
            x1 *= w;
            x2 *= w;
            y1 *= h;
            y2 *= h;
          }

          // Clamp to canvas
          x1 = Math.max(0, Math.min(w, x1));
          y1 = Math.max(0, Math.min(h, y1));
          x2 = Math.max(0, Math.min(w, x2));
          y2 = Math.max(0, Math.min(h, y2));

          const bw = x2 - x1;
          const bh = y2 - y1;
          if (bw <= 2 || bh <= 2) continue;

          // Box
          octx.strokeStyle = "#00ff66";
          octx.strokeRect(x1, y1, bw, bh);

          // Label
          const text = `${label} ${(score * 100).toFixed(0)}%`;
          const tw = octx.measureText(text).width;

          octx.fillStyle = "rgba(0,0,0,0.6)";
          octx.fillRect(x1, Math.max(0, y1 - 22), tw + 10, 22);

          octx.fillStyle = "#00ff66";
          octx.fillText(text, x1 + 5, Math.max(14, y1 - 6));
        }
      }

      function prepareInputTensor() {
        // Draw current frame into 640x640 (stretched)
        offctx.drawImage(video, 0, 0, INPUT_SIZE, INPUT_SIZE);
        const img = offctx.getImageData(0, 0, INPUT_SIZE, INPUT_SIZE).data;

        // Convert to Float32 NCHW [1,3,640,640], normalized to 0..1
        const float = new Float32Array(1 * 3 * INPUT_SIZE * INPUT_SIZE);
        const area = INPUT_SIZE * INPUT_SIZE;

        for (let i = 0; i < area; i++) {
          const r = img[i * 4 + 0] / 255;
          const g = img[i * 4 + 1] / 255;
          const b = img[i * 4 + 2] / 255;

          float[i + 0 * area] = r;
          float[i + 1 * area] = g;
          float[i + 2 * area] = b;
        }

        return new ort.Tensor("float32", float, [1, 3, INPUT_SIZE, INPUT_SIZE]);
      }

      async function loop() {
        if (!running) return;

        const t0 = performance.now();

        // resize overlay to match actual displayed video pixels
        if (
          overlay.width !== video.videoWidth ||
          overlay.height !== video.videoHeight
        ) {
          overlay.width = video.videoWidth;
          overlay.height = video.videoHeight;
        }

        const inputTensor = prepareInputTensor();
        const feeds = { [inputName]: inputTensor };

        const results = await session.run(feeds);
        const outputName = session.outputNames[0];
        const output = results[outputName].data; // Float32Array

        const boxes = processOutput(output, overlay.width, overlay.height);
        drawBoxes(boxes);

        const dt = performance.now() - t0;
        hud.textContent = `boxes: ${boxes.length}\nms/frame: ${dt.toFixed(1)}`;
        console.log(boxes);
        requestAnimationFrame(loop);
      }

      async function start() {
        startBtn.disabled = true;
        hud.textContent = "loading model…";

        // Webcam
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" },
          audio: false,
        });
        video.srcObject = stream;
        await video.play();

        // Load ONNX model (must be hosted)
        // For iPhone Safari, WASM is typically the fallback (slower).
        session = await ort.InferenceSession.create("./yolov8n.onnx", {
          executionProviders: ["wasm"],
        });

        inputName = session.inputNames[0];

        hud.textContent = "running…";
        running = true;
        loop();
      }

      startBtn.addEventListener("click", start);
    </script>
  </body>
</html>
